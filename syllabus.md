syllabus.md

# Syllabus

## Session 1: What went wrong with this case? 

### Mandatory readings 
* [The case study](/2022-casestudy-algo.md)
* Hao, K. (2020, 20 August). [The UK exam debacle reminds us that algorithms can’t fix broken systems](https://www.technologyreview.com/2020/08/20/1007502/uk-exam-algorithm-cant-fix-broken-system). _MIT Technology Review_. 

## Session 2: Ensuring the technical accuracy of an algorithmic system

* Guest speakers: Quentin Loridant and Pierre Camilleri (data scientist at cooperative Multi)

### Mandatory readings
* Angwin, J., Larson, J., Mattu, S., Kirchner, L. (2016, 23 May). [Machine Bias: There’s software used across the country to predict future criminals. And it’s biased against blacks](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing). _ProPublica_. 
* Dressel, J. and Farid, Hany. (2018). [The accuracy, fairness, and limits of predicting recidivism](https://www.science.org/doi/10.1126/sciadv.aao5580). _Science Advances_.  
* Leufer, D. (2020). [_Myth: AI can be objective or unbiased_](https://www.aimyths.org/ai-can-be-objective-or-unbiased#bias-in-machine-learning). AI Myths.
* Ofqual. (2020). [_Executive summary, Student-level equalities analyses for GCSE and A level, Summer 2020_](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/938869/6713_Student-level_equalities_analyses_for_GCSE_and_A_level.pdf). pp. 5-8.  
* O’Neil, C. (2016). Introduction and Chapter 1: “Bomb parts: What is a model?”. In _Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy_.
* Stoyanovich, J. and Arif Khan, F. (2021). [All about that Bias](https://dataresponsibly.github.io/we-are-ai/comics/vol4_en.pdf). _We are AI Comics_, Vol 4.   
* Vogl, T. (2021). Algorithmic decision assistance in children’s social care: Questioning the consistency of tools across UK local authorities. [Video](https://youtu.be/zW8KV-‘zjx7g?t=9649) from the conference “L’Etat digital: numérisation de l’administration publique et administration publique numérique”. (2:40:45 - 2:53:45)

### Optional readings
* Bennett, S. H. (2020, 20 August). [On A-Levels, Ofqual and Algorithms](https://www.sophieheloisebennett.com/posts/a-levels-2020/). _Sophie Bennett’s blog_.   
* Corbett-Davies, S., Pierson, E., Feller, A., Goel, S. (2016, October 17). [A computer program used for bail and sentencing decisions was labeled biased against blacks. It’s actually not that clear](https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/). _The Washington Post_.
* Narayan, A. (2018). [Tutorial: 21 Definitions of Fairness and their politics](https://www.youtube.com/watch?v=wqamrPkF5kk). Video from the 2018 conference on Fairness, Accountability and Transparency of Machine Learning. 
* Ofqual. (2020, 15 April). [_Equality Impact Assessment_](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/879605/Equality_impact_assessment_literature_review_15_April_2020.pdf).
* Selbst, A., boyd, d., Friedler, S., Venkatasubramanian, S., Vertesi, J. (2019). [Fairness and Abstraction in Sociotechnical Systems](https://dl.acm.org/doi/pdf/10.1145/3287560.3287598). Proceedings from the 2019 conference on Fairness, Accountability and Transparency of Machine Learning, Atlanta.  
* Suresh, H. and John Guttag. (2020). [A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle](https://arxiv.org/abs/1901.10002). Proceedings from the 2020 conference on Fairness, Accountability and Transparency of Machine Learning, Barcelona.  

## Session 3 : Assessing the impacts of an algorithmic system 

### Mandatory readings (policy instruments)
* [Canadian Algorithmic Impact Assessment](https://open.canada.ca/aia-eia-js/?lang=en) 
* [Dubai’s AI Ethics Self Assessment tool](https://www.digitaldubai.ae/self-assessment) 
* [New Zealand’s Algorithmic Charter](https://data.govt.nz/assets/data-ethics/algorithm/Algorithm-Charter-2020_Final-English-1.pdf) (for context, see [this presentation page](https://data.govt.nz/toolkit/data-ethics/government-algorithm-transparency-and-accountability/#algorithmCharter))  
* The Netherlands’ Court of Audit report [_Understanding Algorithms_](https://english.rekenkamer.nl/publications/reports/2021/01/26/understanding-algorithms) 

### Mandatory readings
* Ada Lovelace Institute. (2020, 29 April). [_Examining the Black Box: Tools for assessing algorithmic systems_](https://www.adalovelaceinstitute.org/report/examining-the-black-box-tools-for-assessing-algorithmic-systems/), April 29, 2020. 
* Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). [_Executive Summary. Algorithmic Accountability for the Public Sector_.](https://www.opengovpartnership.org/wp-content/uploads/2021/08/executive-summary-algorithmic-accountability.pdf)  
* Marda, V., and Narayan, S. (2020). [Data in New Delhi’s Predictive Policing System](https://www.vidushimarda.com/storage/app/media/uploaded-files/fat2020-final586.pdf). Proceedings of the 2020 ACM Conference on Fairness, Accountability, and Transparency. 
* The Global Frontier. (2022, 9 March). [Victims denounce failures in VioGén, the algorithm against gender violence](https://theglobalfrontier.com/victims-denounce-failures-in-viogen-the-algorithm-against-gender-violence/). 

### Optional readings
* Chowdhury, R., and Williams, J. (2021, July 30). [Introducing Twitter’s first algorithmic bias bounty challenge](https://blog.twitter.com/engineering/en_us/topics/insights/2021/algorithmic-bias-bounty-challenge). 
* Eticas. (2022). [_The External Audit of the VioGén System_](https://eticasfoundation.org/wp-content/uploads/2022/03/ETICAS-FND-The-External-Audit-of-the-VioGen-System.pdf). 
* Gender Shades. [_How well do IBM, Microsoft, and Face++ AI services guess the gender of a face?_](http://gendershades.org/overview.html). 
* Metcalf, J., Moss, E., Watkins, E. A., Singh, R., Elish, M. C. (2021). [Algorithmic Impact Assessments and Accountability: The Co-construction of Impacts](https://dl.acm.org/doi/abs/10.1145/3442188.3445935). Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency.  

## Session 4 : Building accountability: transparency, explainability, appeal processes

### Mandatory readings (policy instruments) 
* Amsterdam’s [register](https://algoritmeregister.amsterdam.nl/en/ai-register/) 
* Chile’s [register](https://www.algoritmospublicos.cl/)
* Etalab’s [proposed framework for registers](https://guides.etalab.gouv.fr/algorithmes/inventaire/)
* Google [Model Cards](https://modelcards.withgoogle.com/about)    
* Helsinki’s [register](https://ai.hel.fi/en/ai-register/)  
* Ontario’s [register](https://data.ontario.ca/group/artificial-intelligence-andalgorithms) 

### Mandatory readings
* Ananny M, Crawford K. Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability. _New Media & Society_. 2018;20(3):973-989. doi:10.1177/146144481667664
* Green, B., Kak, A. (2021, June 15). [The False Comfort of Human Oversight as an Antidote to A.I. Harm](https://slate.com/technology/2021/06/human-oversight-artificial-intelligence-laws.html). _Slate_. 
* Jansen, F., Cath, C. (2021). Just Do It: on the limits of governance through AI registers. In _AI Snake Oil, Pseudoscience and Hype, edited by Frederike Kaltheuner_. Meat Space Press. Online link: https://arxiv.org/abs/2109.02944 
* Kolkman, D. (2020, August 16). [F**ck the algorithm? What the world can learn from the UK A-level grading algorithm fiasco](https://blogs.lse.ac.uk/impactofsocialsciences/2020/08/26/fk-the-algorithm-what-the-world-can-learn-from-the-uks-a-level-grading-fiasco/). LSE Impact Blog. 

## Session 5 : working with different actors: citizen participation and public procurement 

### Mandatory readings (policy instruments) 
* Amsterdam’s [Standard Clauses for Fair Algorithms](https://www.amsterdam.nl/innovation/digitalisation-technology/algorithms-ai/contractual-terms-for-algorithms/) (and .docx document) 
* UK’s [Guidelines for AI Procurement](https://www.gov.uk/government/publications/guidelines-for-ai-procurement/guidelines-for-ai-procurement) (2021) 
* Information on procurement (p.34 + explanation of the DEEPMAX score) in Tamil Nadu's [Safe and Ethical Use of AI](https://elcot.in/sites/default/files/AIPolicy2020.pdf).  

### Mandatory readings
* Costanza-Chock, S. (2020). [Design Practices: “Nothing about Us without Us.”](https://design-justice.pubpub.org/pub/cfohnud7). In _Design Justice_ (1st ed.).   
* Data Justice Lab. (2021). [_Advancing civic participation in algorithmic decision-making: A guidebook for the public sector_](https://datajusticelab.org/wp-content/uploads/2021/06/PublicSectorToolkit_english.pdf).  
* Elish, M. C. (2020, August 7). [Sepsis Watch in Practice: The labor of disruption and repair in healthcare](https://points.datasociety.net/sepsis-watch-in-practice-5b06f88655fe ). _Data & Society: Points_. 
* Green, B. Z. (2019). [Chapter 6: The Innovative City: The Relationship between Technical and Nontechnical Change in City Government](https://doi.org/10.7551/mitpress/11555.003.0008). In _The Smart Enough City: Putting Technology in Its Place to Reclaim Our Urban Future_. MIT Press. Published: 2019

### Optional readings
* Office for Statistics Regulation Authority. (2021, 2 March). [_Ensuring statistical models command public confidence: Learning lessons from the approach to developing models for awarding grades in the UK in 2020, Executive summary_](https://osr.statisticsauthority.gov.uk/publication/ensuring-statistical-models-command-public-confidence/). 
* Wylie, B. (2018, 13 August). [Searching for the Smart City's Democratic Future](https://www.cigionline.org/articles/searching-smart-citys-democratic-future/). Centre for International Governance Innovation.  

## Session 6 : taking down a problematic algorithm and managing the aftermath - Conclusion of the class

Guest speakers:
* Divij Joshi
* Martha Dark (Foxglove) and Curtis Parfitt Ford

### Mandatory readings
* Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). [_Executive Summary. Algorithmic Accountability for the Public Sector_](https://www.opengovpartnership.org/wp-content/uploads/2021/08/executive-summary-algorithmic-accountability.pdf). (note : already assigned earlier in the year, but have another read!)
* Foxglove. (August 17, 2020). [We put a stop to the A Level grading algorithm!](https://www.foxglove.org.uk/2020/08/17/we-put-a-stop-to-the-a-level-grading-algorithm/). 
* Joshi, D. [AI Observatory](https://ai-observatory.in/). 
* Leufer, D. (2020). [_Myth: AI has agency: headline rephraser tool_](https://www.aimyths.org/ai-has-agency#headline-rephraser). AI Myths. 
* Lulamae, J. (2022). [People are still angry about the UK's 2020 grading algorithm experiment](https://r.algorithmwatch.org/nl3/tnK3o1XF0cFyaf9fHVWtaw?m=AMwAAMY7ZvEAAAAQMhgAAAH66EEAAAAA6uQAAB1gABB0KQBidKt2FY6ovuDyRQ-nbOhWeD8HOwAQJ0I&b=822367f1&e=0b4020f4&x=aALhDVlisnKGlGVxFivX-bk11o6AtUEu-8wM5knkcSk). In Automated Society Newsletter. 
* Ofqual. (2021). [_Decisions on how GCSE, AS and A- level grades will be determined in summer 2021_](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/965005/6747-1_decisions_-_GQ_consultation_on_awarding_grades_in_2021.pdf)
* Poole, S. (2020, 3 September). [Steven Poole’s word of the day: 'Mutant algorithm': boring B-movie or another excuse from Boris Johnson?](https://www.theguardian.com/books/2020/sep/03/mutant-algorithm-boring-b-movie-or-another-excuse-from-boris-johnson). _The Guardian_.  

### Optional reading
* Edwards, L. (2022). [_The EU AI Act: a summary of its significance and scope. Ada Lovelace Institute_](https://www.adalovelaceinstitute.org/wp-content/uploads/2022/04/Expert-explainer-The-EU-AI-Act-11-April-2022.pdf) 
* Green, B. Z. (2019). [Chapter 2: The Livable City: The Limits and Dangers of New Technology](https://doi.org/10.7551/mitpress/11555.003.0004). In _The Smart Enough City: Putting Technology in Its Place to Reclaim Our Urban Future_. MIT Press. 
* Vervloesem, K. (2020, 6 April). [How Dutch activists got an invasive fraud detection algorithm banned](https://algorithmwatch.org/en/syri-netherlands-algorithm/). AlgorithmWatch blog.  
 
## Readings about the technical side of algorithms/AI

Introductory resources
* Jist Studios, BBC Ideas. (2019, 19 September). “What exactly is an algorithm?” [[Video](https://www.bbc.co.uk/ideas/videos/what-exactly-is-an-algorithm/p07nw8ny)].  
* Leufer, D. (2020). [Myth: the term AI has a clear meaning](https://www.aimyths.org/the-term-ai-has-a-clear-meaning). AI Myths.  
* Stoyanovich, J. and Arif Khan, F. (2021). [“What is AI?”](https://dataresponsibly.github.io/we-are-ai/comics/vol1_en.pdf). _We are AI Comics_, Vol 1.  

MOOCs to go deeper 
* https://course.elementsofai.com/
* https://openclassrooms.com/fr/courses/6417031-objectif-ia-initiez-vous-a-lintelligence-artificielle (in French)



