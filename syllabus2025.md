# Syllabus

## Session 1: What went wrong with this case? - Introduction

### Mandatory readings 
* [The case study](/2022-casestudy-algo.pdf)
* Green, B. Z. (2019). [Chapter 6: The Innovative City: The Relationship between Technical and Nontechnical Change in City Government](https://doi.org/10.7551/mitpress/11555.003.0008). In _The Smart Enough City: Putting Technology in Its Place to Reclaim Our Urban Future_. MIT Press. 
* Hao, K. (2020). [The UK exam debacle reminds us that algorithms can’t fix broken systems](https://www.technologyreview.com/2020/08/20/1007502/uk-exam-algorithm-cant-fix-broken-system). _MIT Technology Review_. 
* Toh, A. (2014). [The Algorithms Too Few People Are Talking About](https://www.hrw.org/news/2024/01/05/algorithms-too-few-people-are-talking-about). _Human Rights Watch_.

## Session 2: Avoiding tech pitfalls - errors, choices, biases, (justice?)

### Mandatory readings
* Corbett-Davies, S., Pierson, E., Feller, A., Goel, S. (2016, October 17). [A computer program used for bail and sentencing decisions was labeled biased against blacks. It’s actually not that clear](https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/). _The Washington Post_.
* Dressel, J. and Farid, H. (2018). [The accuracy, fairness, and limits of predicting recidivism](https://www.science.org/doi/10.1126/sciadv.aao5580). _Science Advances_.
* Guo, E., Geiger, G., Braun, J.-C. (2025). [Inside Amsterdam’s high-stakes experiment to create fair welfare AI](https://www.technologyreview.com/2025/06/11/1118233/amsterdam-fair-welfare-ai-discriminatory-algorithms-failure/). _MIT Technology Review_. 
* Leufer, D. (2020). [Myth: AI can be objective or unbiased](https://www.aimyths.org/ai-can-be-objective-or-unbiased#bias-in-machine-learning). _AI Myths_.
* O’Neil, C. (2016). Introduction and Chapter 1: “Bomb parts: What is a model?”. In _Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy_. Crown Publishing Group. 
* Ziosi, M. and Pruss, D. (2024). [Evidence of What, for Whom? The Socially Contested Role of Algorithmic Bias in a Predictive Policing Tool](https://doi.org/10.1145/3630106.3658991). _FAccT '24: Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency_.

### Optional readings
* Bennett, S. H. (2020, 20 August). [On A-Levels, Ofqual and Algorithms](https://www.sophieheloisebennett.com/posts/a-levels-2020/). _Sophie Bennett’s blog_. 
* D'Ignazio, C. and Klein, L. (2020). [2. Collect, Analyze, Imagine, Teach](https://data-feminism.mitpress.mit.edu/pub/ei7cogfn/release/4). In _Data Feminism_. MIT Press. 
* Narayan, A. (2018). [Tutorial: 21 Definitions of Fairness and their politics](https://www.youtube.com/watch?v=wqamrPkF5kk). _Proceedings of the 2018 ACM Conference on Fairness, Accountability, and Transparency_.
* Suresh, H. and Guttag, J. (2020). [A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle](https://arxiv.org/abs/1901.10002). _Proceedings of the 2020 ACM Conference on Fairness, Accountability, and Transparency_. 
* Wachter, S., Mittelstadt, B., Russell, C. (2021). [Bias Preservation in Machine Learning: The Legality of Fairness Metrics Under EU Non-Discrimination Law](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3792772). _West Virginia Law Review, Vol. 123, No 3_.
* Wang, A., Kapoor, S., Barocas, S., Narayanan, A. (2023). [Against Predictive Optimization: On the Legitimacy of Decision-Making Algorithms that Optimize Predictive Accuracy](https://predictive-optimization.cs.princeton.edu/). 
* Documentation on the A-Level algorithm: Ofqual (2020). [_Executive summary, Student-level equalities analyses for GCSE and A level, Summer 2020_](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/938869/6713_Student-level_equalities_analyses_for_GCSE_and_A_level.pdf). pp. 5-8; Ofqual. (2020, 15 April). [_Equality Impact Assessment_](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/879605/Equality_impact_assessment_literature_review_15_April_2020.pdf). 

### Policies, Tools, Standards, and Good Practices
**Concrete resources**
* The City of Amsterdam's [Fairness Handbook](https://amsterdamintelligence.com/resources/the-fairness-handbook), written for its public servants.  
* The EU General-Purpose AI (GPAI) Code of Practice's [Model Documentation Form for general-purpose AI models](https://digital-strategy.ec.europa.eu/en/policies/contents-code-gpai) (scroll down at the bottom of the page). 
* The ["tool specification"](.gov.uk/government/publications/guidance-for-organisations-using-the-algorithmic-transparency-recording-standard/algorithmic-transparency-recording-standard-guidance-for-public-sector-bodies#tool-specification-tier-2) section of the United Kingdom's Algorithmic Transparency Recording Standard. 
* The European Data Protection Board's guide on [_AI-Complex Algorithms and effective Data Protection Supervision: Bias evaluation_](https://www.edpb.europa.eu/system/files/2025-01/d1-ai-bias-evaluation_en.pdf) (written by Dr. Kris Shrishak). 
* The European Data Protection Board's [_Checklist for AI Auditing_](https://www.edpb.europa.eu/system/files/2024-06/ai-auditing_checklist-for-ai-auditing-scores_edpb-spe-programme_en.pdf) (written by Dr. Gemma Galdon Clavell). 
* Balayn, A., Gürses, S. (2021). [Beyond Debiasing: Regulating AI and its inequalities](https://edri.org/wp-content/uploads/2021/09/EDRi_Beyond-Debiasing-Report_Online.pdf). _EDRi_. 

**Standards and Laws**
* International standards: [IEEE Standard for Algorithmic Bias Considerations (7003-2024)](https://ieeexplore.ieee.org/document/10851955), [ISO/IEC TR 24027:2021 - Bias in AI systems and AI aided decision making](https://www.iso.org/standard/77607.html). - Note: you have to buy those, but this is so you have an idea of the current state of standards. 
* NIST's [documentation on bias](https://www.nist.gov/artificial-intelligence/ai-research-identifying-managing-harmful-bias-ai).
* [Article 10 of the EU AI Act](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32024R1689&qid=1724384177230). 

## Session 3: Assessing the impacts 

### Mandatory readings
* Ada Lovelace Institute. (2020). [Examining the Black Box: Tools for assessing algorithmic systems](https://www.adalovelaceinstitute.org/report/examining-the-black-box-tools-for-assessing-algorithmic-systems/). 
* Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). [Executive Summary. Algorithmic Accountability for the Public Sector.](https://www.opengovpartnership.org/wp-content/uploads/2021/08/executive-summary-algorithmic-accountability.pdf).
* Constantaras, E., Geiger, G., Braun, J.-C., Mehrotra, D., Aung, H. (2023). [Inside the Suspicion Machine](https://www.wired.com/story/welfare-state-algorithms/). _Wired_.
* Costanza-Chock, S., Raji, I. D., Buolamwini, J. (2022). [Who Audits the Auditors? Recommendations from a field scan of the algorithmic auditing ecosystem](https://dl.acm.org/doi/abs/10.1145/3531146.3533213). _FAccT '22: Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency_.
* Groves, L., Metcalf, J., Kennedy, A., Vecchione, B., Strait, A. (2024). [Auditing work: Exploring the New York City algorithmic bias audit regime](https://doi.org/10.1145/3630106.3658959). In *Proceedings of the Association for Computing Machinery*. Association for Computing Machinery. 
* Riley, S. (2024). [Overriding (in)justice: Pretrial risk assessment administration on the frontlines](https://doi.org/10.1145/3630106.3658920). _FAccT '24: Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency_. 

### Optional readings/listen
* Ada Lovelace Institute. (2025). [Going Pro? Considerations for the emerging field of AI assurance](https://www.adalovelaceinstitute.org/report/going-pro/). - For an overview of the current state of the field of "AI assurance". 
* Braun, J.-C., Constantaras, E., Haung, H., Geiger, G., Mehrotra, D., Howden, D. (2023). [Suspicion Machines Methodology: A detailed explainer on what we did and how we did it](https://www.lighthousereports.com/suspicion-machines-methodology/). _Lighthouse Reports_. - For a methodology deep-dive on how data journalists audited a risk-assessment algorithm for bias (here, in the Dutch context).
* Elish, M. C. (2020). [Sepsis Watch in Practice: The labor of disruption and repair in healthcare](https://web.archive.org/web/20210316044439/https://points.datasociety.net/sepsis-watch-in-practice-5b06f88655fe?gi=9e0f4a4c87e9). _Data & Society: Points_. - For an account of why assessments are in context are important. 
* Gender Shades. [How well do IBM, Microsoft, and Face++ AI services guess the gender of a face?](http://gendershades.org/overview.html). - For an example of one the first third-party technical audits. 
* Marda, V., and Narayan, S. (2020). [Data in New Delhi’s Predictive Policing System](https://www.vidushimarda.com/storage/app/media/uploaded-files/fat2020-final586.pdf). _Proceedings of the 2020 ACM Conference on Fairness, Accountability, and Transparency_.  - For an example of what it is possible to do even without access to algorithms (here, in the Indian context).
* Reply All Podcast. (2018). [Episodes 127 and 128: The Crime Machine](https://www.metafilter.com/177101/Reply-All-episode-127-and-128-The-Crime-Machine). _Gimlet Media_. - For an example of how metrics can impact policies.  
* Varon, J. and Peña, P. (2022). [Not My A.I.: Towards Critical Feminist Frameworks To Resist Oppressive A.I. Systems](https://www.hks.harvard.edu/sites/default/files/2023-11/22_10JoanaVaron.pdf). Carr Center for Human Rights Policy, Harvard Kennedy School, Harvard University. - For a non-institutional vision of impacts. 

### Policies, Tools, Standards, and Good Practices
**Examples of impact assessments**
* UNESCO's [Ethical Impact Assessment](https://www.unesco.org/ethics-ai/en/eia).
* Canada's [Algorithmic Impact Assessment](https://open.canada.ca/aia-eia-js/?lang=en). See for instance the impact assessment for the ["advanced analytics triage of overseas temporary resident visa applications"](https://open.canada.ca/data/en/dataset/6cba99b1-ea2c-4f8a-b954-3843ecd3a7f0).
* New Zealand’s [Algorithmic Charter](https://data.govt.nz/assets/data-ethics/algorithm/Algorithm-Charter-2020_Final-English-1.pdf) (for context, see [this presentation page](https://data.govt.nz/toolkit/data-ethics/government-algorithm-transparency-and-accountability/#algorithmCharter)).
* Australia's [National Framework for the Assurance of Artificial Intelligence in Government](https://www.finance.gov.au/government/public-data/data-and-digital-ministers-meeting/national-framework-assurance-artificial-intelligence-government/implementing-australias-ai-ethics-principles-government). 

**On environmental impacts** 
* Sustainable AI Coalition (2025). [Standardization for AI Environmental Sustainability: Towards a coordinated global approach](https://www.sustainableaicoalition.org/wp-content/uploads/Standardization_AI_Sustainability.pdf). - For an example of (institutional) 

**Examples of institutional audits**
* Dutch Data Protection Authority - Department for the Coordination of Algorithmic Oversight (DCA). (2024). [_AI & Algorithmic Risks Report Netherlands_](https://www.autoriteitpersoonsgegevens.nl/uploads/2024-01/AI%20%26%20Algorithmic%20Risks%20Report%20Netherlands%20-%20winter%202023%202024.pdf) - for an example of how national authorities can practice "algorithmic oversight".
* Supreme Audit Institutions of Finland, Germany, the Netherlands, Norway and the UK, [_Auditing machine learning algorithms: A white paper for public auditors_](https://www.auditingalgorithms.net/) (2023) - for an example of how Courts of Audits can tackle the issue. 

**Examples of explainers/primers to familiarize public servants with issues and impacts**
* Chen, B. (2025). [Policy Brief: Dispelling Myths of AI and Efficiency](https://datasociety.net/library/dispelling-myths-of-ai-and-efficiency/). _Data & Society_. - for an example of a policy brief, US-oriented. 
* Dent, A. (2024). [Automating public services: a careful approach](https://static1.squarespace.com/static/5dc968e72502ee46b88c1a4a/t/679b992a3492ca75c33c3c79/1738250539317/Automating%2BPublic%2BServices%2BA%2Bcareful%2Bapproach%2BJuly%2B24.pdf). _Promising Trouble_. - for another example of a policy brief, UK-oriented. 
coordination efforts around environmental impact assessments of AI. 

**An example of impact assessment in context**
* Ada Lovelace Institute. (2024). [Critical Analytics? Learning from the early adoption of data analytics for local authority service delivery](https://www.adalovelaceinstitute.org/wp-content/uploads/2024/10/Ada-Lovelace-Institute-Critical-analytics-July-2024.pdf). - For an example of second-party auditing in context.

**An example in the law**  
* Article 27 of the EU AI Act and CEDPO. (2025). [Fundamental Rights Impact Assessments: What are they? How do they work?](https://cedpo.eu/wp-content/uploads/CEDPO-micro-insight-paper-fundamental-rights-impact-assessments.pdf). _CEDPO AI and Data Working Group Micro-Insights Series_.  

## Session 4: Building Accountabiilty through "AI governance" (transparency, appeals, public procurement)

### Mandatory readings
* Ananny M, Crawford K. [Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability](https://journals.sagepub.com/doi/10.1177/1461444816676645). _New Media & Society_. 
* Brandusescu, A., Sieber, R. E. (2025). [Design versus reality: assessing the results and compliance of algorithmic impact assessments](https://link.springer.com/article/10.1007/s44206-025-00221-7). _Digital Society_. 
* Green, B., Kak, A. (2021). [The False Comfort of Human Oversight as an Antidote to A.I. Harm](https://slate.com/technology/2021/06/human-oversight-artificial-intelligence-laws.html). _Slate_. 
* Jansen, F., Cath, C. (2021). [Just Do It: on the limits of governance through AI registers](https://arxiv.org/abs/2109.02944). In _AI Snake Oil, Pseudoscience and Hype, edited by Frederike Kaltheuner_. Meat Space Press.  
* Kolkman, D. (2020). [F**ck the algorithm? What the world can learn from the UK A-level grading algorithm fiasco](https://blogs.lse.ac.uk/impactofsocialsciences/2020/08/26/fk-the-algorithm-what-the-world-can-learn-from-the-uks-a-level-grading-fiasco/). _LSE Impact Blog_. 
* Rodelli, C., Chander, S. (2025). [One Year On, EU AI Act Collides with New Political Reality](https://www.techpolicy.press/one-year-on-eu-ai-act-collides-with-new-political-reality/). _Tech Policy Press_. 

### Optional readings
* Feathers, T. (2023). [It takes a small miracle to learn basic facts about government algorithms](https://themarkup.org/hello-world/2023/04/01/it-takes-a-small-miracle-to-learn-basic-facts-about-government-algorithms). _The Markup_.
* Johnson, N., Silva, E., Leon, H., Eslami, M., Schwanke, B., Dotan, R., Heidari, H. (2025). [Legacy Procurement Practices Shape How U.S. Cities Govern AI: Understanding Government Employees' Practices, Challenges, and Needs](https://arxiv.org/abs/2411.04994). _FAccT '25: Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency_. 
* Parmar, T. (2025). [Government Documents Show Police Disabling AI Oversight Tools](https://www.motherjones.com/criminal-justice/2025/08/axon-police-ai-draft-one-foia/). _MotherJones_.
* Pénicaud, S. (2025). [Making Algorithm Registers Work for Meaningful Transparency](https://iaciudadana.org/2025/03/13/making-algorithm-registers-work-for-meaningful-transparency/). _IA Ciudadana_.
* Wright, L., Muenster, R. M., Vecchione, B., Qu, T., Cai, P. (S.), Smith, A., Comm 2450 Student Investigators, Metcalf, J., & Matias, J. N. (2024). [Null compliance: NYC Local Law 144 and the challenges of algorithm accountability](https://dl.acm.org/doi/10.1145/3630106.3658920). _FAccT '24: Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency_. 
* Yew, R., Marino, B., Venkatasubramanian, S. (2025). [Red Teaming AI Policy: A Taxonomy of Avoision and the EU AI Act](https://arxiv.org/abs/2506.01931).  _FAccT '25: Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency_. 

### Policies, Tools, Standards, and Good Practices
**Registers**
* [The Algorithm Register of the Dutch government](https://algoritmes.overheid.nl/en). 
* Chile’s [register](https://www.algoritmospublicos.cl/).
* The UK's [Algorithmic Transparency Recording Standard Hub](https://www.gov.uk/government/collections/algorithmic-transparency-recording-standard-hub).
* You can also look through the [government AI registers listed in the Civic Tech Field Guide](https://directory.civictech.guide/listing-category/registers-of-government-ai). 

**Procurement practices**
* ChileCompra's [Standard Bidding Terms for algorithms and artificial intelligence with ethical requirements](https://goblab.uai.cl/en/chilecompra-presents-unprecedented-standard-bidding-terms-for-algorithms-and-artificial-intelligence-with-ethical-requirements/).
* [EU model contractual AI clauses to pilot in procurements of AI](https://public-buyers-community.ec.europa.eu/communities/procurement-ai/resources/eu-model-contractual-ai-clauses-pilot-procurements-ai).
* Pakzad, R., and Conti-Cook, C. (2025). [Key Considerations When Procuring AI in the Public Sector](https://static1.squarespace.com/static/5d159d288addab0001036c45/t/6890f9066bf93951bedd9485/1754331401682/AI_Procurement_Taraaz_CRCR_2025.pdf). Taraaz & The Collaborative Research
Center for Resilience (CRCR). 
* The [resources of the GovAI Coalition](https://www.sanjoseca.gov/your-government/departments-offices/information-technology/artificial-intelligence-inventory/govai-coalition/templates-resources) for local governments (US context). 
* UK’s [Guidelines for AI Procurement](https://www.gov.uk/government/publications/guidelines-for-ai-procurement/guidelines-for-ai-procurement). (2021) 
* [IEEE Standard for the Procurement of Artificial Intelligence and Automated Decision Systems](https://standards.ieee.org/ieee/3119/10729/). 

**Redress**
_There are few examples of good appeal and redress. This report by Doteveryone, although focused on online services, is a good source of inspiration, especially in its recommendations._
* Massey, J., Pope, R. Kitcher, H., Miller, C. (2020). [Better Redress for the Digital Age](https://doteveryone.org.uk/wp-content/uploads/2020/05/Better-Redress-for-the-Digital-Age.pdf). _Doteveryone_.


## Session 5: Ensuring meaningful participation 

### Mandatory readings
* Attard-Frost, B. (2023). [AI Countergovernance](https://www.midnightsunmag.ca/ai-countergovernance/). _Midnight Sun_. 
* Costanza-Chock, S. (2020). [Design Practices: “Nothing about Us without Us.”](https://design-justice.pubpub.org/pub/cfohnud7). In _Design Justice_.
* Hu, W. and Singh, R. (2024). [Enrolling Citizens: A Primer on Archetypes of Democratic Engagement with AI](https://datasociety.net/wp-content/uploads/2024/06/DS_Enrolling-Citizens-Primer_FINAL.pdf). _Data & Society_.  
* Robinson, D. G. (2022). "Chapter 2: Democracy on the Drawing Board" and Conclusion. _Voices in the Code_. Russell Sage Foundation. 
* Sloane, M., Moss, E., Awomolo, O., Forlano, L. (2022). [Participation is not a Design Fix for Machine Learning](https://dl.acm.org/doi/10.1145/3551624.3555285). _EAAMO '22: Proceedings of the 2nd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization_.
* Young, M. (2025). [Gear Shift: Driving Change in Public Sector Technolgoy through Community Input](https://datasociety.net/wp-content/uploads/2025/06/DS_Gear-Shift-Primer-Final.pdf).  

### Optional readings
* Carollo, M., Tanen, B. (2023). [How a Group of Health Executives Transformed the Liver Transplant System](https://themarkup.org/organ-failure/2023/03/21/how-a-group-of-health-executives-transformed-the-liver-transplant-system). _The Markup_. 
* Cardullo, P., Kitchin, Rob. (2019). [Being a 'citizen' in the smart city: up and down the scaffold of smart citizen participation in Dublin, Ireland](https://link.springer.com/article/10.1007/s10708-018-9845-8). _GeoJournal_. 
* Office for Statistics Regulation Authority. (2021). [Ensuring statistical models command public confidence: Learning lessons from the approach to developing models for awarding grades in the UK in 2020, Executive summary](https://osr.statisticsauthority.gov.uk/publication/ensuring-statistical-models-command-public-confidence/). 
* Ofqual. (2020). [Analysis of Consulation Responses: Exceptional arrangements for exam grading and assessment in 2020](https://www.gov.uk/government/consultations/exceptional-arrangements-for-exam-grading-and-assessment-in-2020#history). 
* Wylie, B. (2018, 13 August). [Searching for the Smart City's Democratic Future](https://www.cigionline.org/articles/searching-smart-citys-democratic-future/). Centre for International Governance Innovation.

### Policies, Tools, Standards, & Good Practices
**Literacy**
* [AI and discrimination course in France](https://www.coe.int/fr/web/inclusion-and-antidiscrimination/ai-and-discrimination-course-in-france), by the Council of Europe and the French Equality Body (Défenseur des Droits).
* [UNESCO's Global AI Training](https://www.unesco.org/en/articles/unescos-global-ai-training-empowers-civil-servants-31-countries-revolutionize-public-services).  
**Frameworks**
* ECNL's [Framework for Meaningful Engagement: Human Rights Impact Assessments of AI](https://ecnl.org/publications/framework-meaningful-engagement-human-rights-impact-assessments-ai).
* [Connected by Data's Toolkit: Worker voice in public sector procurement of digital and AI systems in Wales](https://connectedbydata.org/assets/resources/Toolkit%20Procurement.pdf). - For an example of worker involvement. 
* Data Justice Lab. (2021). [Advancing civic participation in algorithmic decision-making: A guidebook for the public sector](https://datajusticelab.org/wp-content/uploads/2021/06/PublicSectorToolkit_english.pdf).
* Gilman, M. (2023). [Democratizing AI: Principles for Meaningful Public Participation](https://datasociety.net/wp-content/uploads/2023/09/DS_Democratizing-AI-Public-Participation-Brief_9.2023.pdf). _Data & Society_.

**Concrete Examples**
* [Connected by Data's People Panel on AI](https://connectedbydata.org/assets/projects/peoplespanel/2024%20-%20Peoples%20Panel%20on%20AI%20-%20Final%20Report%20%2810%20Pages%29.pdf). - For a concrete example of participatory general principles. 
* [Long Beach's LB Co-Lab program](https://www.longbeach.gov/smartcity/pilot-programs/lb-co-lab/). - For a concrete example of permanent participation. 
* Ofqual. (2020). [Analysis of Consultation Responses: Exceptional arrangements for exam grading and assessment in 2020](https://assets.publishing.service.gov.uk/media/5ec650d486650c76b02b2cca/Analysis_of_consultation_responses_21MAY2020.pdf). - As a potential counterexample. 

## Session 6: Taking down a system and managing the aftermath - Conclusion

### Mandatory readings
* Ehsan, U., Singh, R., Metcalf, J., & Riedl, M. (2022). [The algorithmic imprint](https://doi.org/10.1145/3531146.3533186).  _FAccT '22: Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency_.  
* Foxglove. (2020, 17 August). [We put a stop to the A Level grading algorithm!](https://www.foxglove.org.uk/2020/08/17/we-put-a-stop-to-the-a-level-grading-algorithm/). 
* Leufer, D. (2020). [Myth: AI has agency: headline rephraser tool](https://www.aimyths.org/ai-has-agency#headline-rephraser). AI Myths. 
* Ofqual. (2021). [_Decisions on how GCSE, AS and A- level grades will be determined in summer 2021_](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/965005/6747-1_decisions_-_GQ_consultation_on_awarding_grades_in_2021.pdf).
* Poole, S. (2020, September 3). [Steven Poole’s word of the day: 'Mutant algorithm': boring B-movie or another excuse from Boris Johnson?](https://www.theguardian.com/books/2020/sep/03/mutant-algorithm-boring-b-movie-or-another-excuse-from-boris-johnson). _The Guardian_.  
* Redden, J. (2022). [Government's use of automated decision-making systems reflects systemic issues of injustice and inequality](https://theconversation.com/governments-use-of-automated-decision-making-systems-reflects-systemic-issues-of-injustice-and-inequality-185953). _The Conversation_.

### Optional readings
* Green, B. Z. (2019). [Chapter 2: The Livable City: The Limits and Dangers of New Technology](https://doi.org/10.7551/mitpress/11555.003.0004). In _The Smart Enough City: Putting Technology in Its Place to Reclaim Our Urban Future_. MIT Press. 
* Johnson, N., Moharana, S., Harrington, C., Andalibi, N., Heidari, H., Eslami, M. (2025). [The Fall of an Algorithm: Characterizing the Dynamics Toward Abandonment](https://arxiv.org/pdf/2404.13802). _FAccT '25: Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency_. 
* Lulamae, J. (2022). [People are still angry about the UK's 2020 grading algorithm experiment](https://r.algorithmwatch.org/nl3/tnK3o1XF0cFyaf9fHVWtaw?m=AMwAAMY7ZvEAAAAQMhgAAAH66EEAAAAA6uQAAB1gABB0KQBidKt2FY6ovuDyRQ-nbOhWeD8HOwAQJ0I&b=822367f1&e=0b4020f4&x=aALhDVlisnKGlGVxFivX-bk11o6AtUEu-8wM5knkcSk). _AlgorithmWatch's Automated Society_.

### Examples of resistance
**France**
* Amnesty International. (2024). [France: CNAF State Council Complaint](https://www.amnesty.org/fr/documents/eur21/8795/2024/en/). (and an article covering it in _Wired_: Meaker, M. (2024). [Algorithms Policed Welfare Systems for Years. Now They're Under Fire for Bias](https://www.wired.com/story/algorithms-policed-welfare-systems-for-years-now-theyre-under-fire-for-bias/)).

**The Netherlands**
* Vervloesem, K. (2020, April 6). [How Dutch activists got an invasive fraud detection algorithm banned](https://algorithmwatch.org/en/syri-netherlands-algorithm/). _AlgorithmWatch_.
* Adelmant, V., van Veen, C. (2022). [Hollow rights victories? Dutch struggles against digital injustice](https://www.openglobalrights.org/Dutch-struggles-against-injustice-digital-rights-netherlands/). _Open Global Rights_.  

**The US**
* The [Stop LAPD Spying Coalition](https://stoplapdspying.org/).
* Surveillance Resistance Lab. [MyCity, INC. A Case Against "CompStat Urbanism"](https://surveillanceresistancelab.org/wp-content/uploads/MyCityINC_March2024.pdf).

**The UK**
* [Public Law Project's Tracking Automated Government register](https://publiclawproject.org.uk/resources/the-tracking-automated-government-register/). 