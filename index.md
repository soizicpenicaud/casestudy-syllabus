<meta property="og:image" content="imagepreview.png" />
<meta property="twitter:image" content="imagepreview.png" />

## Responsible Use of Decision-Making Algorithms in the Public Sector: a Case Study Approach

Course designed and taught by [Soizic Pénicaud](https://twitter.com/soizicpenicaud) at [Sciences Po Paris' Graduate School of Public Affairs](https://www.sciencespo.fr/public/en.html) in the Fall semester of 2021 - 2025.

The content of this course and the case study are available under the Creative Commons Attribution-Non Commercial 4.0 International licence. 

## Course description

“Artificial intelligence” is a buzzword in the public sector, and agencies increasingly use algorithms and data-driven systems to aid or make decisions. This course is suited for students who want to understand the issue and apply their takeaways to policy, advocacy, research or product management work.
The course’s starting point is an algorithm developed by the English government in 2020 to predict A-Level grades, and the backlash that ensued. Other cases are discussed to go deeper into specific aspects of designing and implementing algorithms.

The main questions addressed are: when (not) to build algorithms? For and with whom? How to
ensure their efficacy and monitor their actual impact, especially with regards to inequalities? How to ensure government remains accountable? What role does civil society play, and how can it push back against abuses? 

## Course structure

The course is structured around the case of the algorithm developed by the English government for A-Level exam
results at the beginning of the Covid-19 pandemic, and the backlash that ensued. Other cases will be
studied to go deeper into specific aspects of designing and implementing algorithms.

|----|----|
|**Session**|**Objective in a nutshell**|
|**What went wrong with this case?**|Understand the details of the case <br> Replace algorithms in their public policy, political contexts <br> Understand what went wrong politically with the A-Levels case <br>|
|**Avoiding tech pitfalls - errors, choices, biases, (justice?)**|Delve into the technical aspects of algorithms and the choices they entail <br>  Understand the concept of fairness and its limitations <br> Understand what went wrong technically with the A-Levels algorithm<br>|  
|**Assessing the impacts of an algorithmic system**|Learn about and critique existing policy instruments and tools to assess the impacts of algorithmic systems <br> Learn about different methods to investigate and audit algorithmic systems <br> Reflect on how these concepts apply to the A-Levels case <br>|
|**Building accountability: transparency, appeals, public procurement**|Understand what accountability means and how it compares to transparency, fairness or explainability <br> Explore different ways to ensure government remains accountable, and understand their limitations and ambiguities <br>|
|**Ensuring meaningful participation**|Understand the breadth and types of actors involved in designing, building and using algorithmic systems <br>Explore citizen participation in the context of data-driven systems and be aware of the pitfalls of "participation washing" <br>|
|**Taking down a problematic algorithmic system and managing the aftermath**|Understand the longer-lasting consequences of algorithmic systems, even when cancelled <br>Reflect on Boris Johnson's communication around the A-Level scandal <br> Hear from guest speakers about their experience researching, litigating and fighting back against algorithmic systems <br>|

## Case study (PDF)

[Read the case study about the 2020 A-Level grade prediction algorithm](/ResponsibleAI_CaseStudy_2024.pdf).

## Syllabus

For the detailed syllabus, see the [dedicated page](/syllabus2025.md). 

## Case studies for presentations

See [the case studies students will present on](/casestudies.md).
